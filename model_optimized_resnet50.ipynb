{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Data augmentation is a technique for generating new data samples from existing samples by applying random transformations. This helps the model become more robust and generalize better to unseen data. Explanation of the transformations:\n",
    "\n",
    "- `RandomHorizontalFlip()`: Randomly flips some of the images horizontally.\n",
    "- `RandomRotation(10)`: Randomly rotates some images within a range of Â±10 degrees.\n",
    "- `ColorJitter()`: Randomly adjusts the brightness, contrast, saturation, and hue of the images.\n",
    "- `RandomAffine()`: Applies random affine transformations, including translation within a range of 10% of the image.\n",
    "\n",
    "These transformations increase the diversity of the training data, helping to prevent overfitting and improving the model's ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungCancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        self.labels = {\"adenocarcinoma\": 0, \"large.cell.carcinoma\": 1, \"normal\": 2, \"squamous.cell.carcinoma\": 3}\n",
    "        self.filepaths = []\n",
    "        self.targets = []\n",
    "        for label, idx in self.labels.items():\n",
    "            paths = glob.glob(f\"{root_dir}/{label}/*.png\")\n",
    "            self.filepaths.extend(paths)\n",
    "            self.targets.extend([idx] * len(paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.filepaths[index]\n",
    "        img = cv2.imread(filepath)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.targets[index]\n",
    "        return img, label\n",
    "    \n",
    "    def show_images(self, num_images=6, rows=2):\n",
    "        \"\"\"Display a grid of images randomly selected from the dataset.\"\"\"\n",
    "        cols = num_images // rows\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 5))\n",
    "        indices = random.sample(range(len(self)), num_images)\n",
    "\n",
    "        for ax, idx in zip(axes.flatten(), indices):\n",
    "            img, label = self[idx]  # Get the image and label\n",
    "            \n",
    "            img = img.numpy().transpose((1, 2, 0))  # Convert to numpy array and correct the channel order\n",
    "            mean = np.array([0.5, 0.5, 0.5])\n",
    "            std = np.array([0.5, 0.5, 0.5])\n",
    "            img = std * img + mean  # Unnormalize\n",
    "            img = np.clip(img, 0, 1)  # Clip the image pixel values\n",
    "            \n",
    "            ax.imshow(img)\n",
    "            ax.axis('on')  # Turn off axis\n",
    "            label_name = list(self.labels.keys())[list(self.labels.values()).index(label)]  # Get label name\n",
    "            ax.set_title(label_name)\n",
    "        \n",
    "        # Reduce padding\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0.2)  # Adjust the spacing between images\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LungCancerDataset(root_dir='./data/train')\n",
    "valid_dataset = LungCancerDataset(root_dir='./data/valid')\n",
    "\n",
    "train_count = Counter(train_dataset.targets)\n",
    "valid_count = Counter(valid_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nimages(dataset, count, name):\n",
    "    class_names = list(dataset.labels.keys())\n",
    "    counts = [count[dataset.labels[class_name]] for class_name in class_names]\n",
    "\n",
    "    colors = plt.cm.Pastel1(np.linspace(0, 1, len(class_names)))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        plt.bar(class_name, counts[i], color=colors[i])\n",
    "\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Images')\n",
    "\n",
    "    for index, value in enumerate(counts):\n",
    "        plt.text(index, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_nimages(train_dataset, train_count, name='Train data')\n",
    "plot_nimages(valid_dataset, valid_count, name='Valid data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show_images(num_images=8, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModifiedResNet50 Architecture Explanation\n",
    "\n",
    "The ModifiedResNet50 is an adaptation of the standard ResNet50 architecture, tailored for a specific classification task with four classes. The ResNet50 model is a deep convolutional neural network that is 50 layers deep, designed to address the vanishing gradient problem by incorporating residual connections. Here's a detailed explanation of the modifications and the overall architecture:\n",
    "\n",
    "### Base Model: ResNet50\n",
    "\n",
    "- **Pretrained Weights**: The model uses pretrained weights on ImageNet, which helps in leveraging transfer learning. This means the model has already learned to extract useful features from a large and diverse dataset.\n",
    "\n",
    "### Custom Modifications\n",
    "\n",
    "1. **Output Layer Adjustment**:\n",
    "    - The original ResNet50 model's fully connected (fc) layer is designed for 1000 classes. In this modified version, the final fully connected layer is replaced to output four classes.\n",
    "    - **`nn.Linear` Layer**: This layer is changed to have the appropriate output size for the task (`num_classes=4`).\n",
    "    - **`nn.Dropout` Layer**: A dropout layer with a rate of 0.5 is added before the final fully connected layer to help prevent overfitting. Dropout randomly sets a fraction of the input units to 0 at each update during training time, which helps in regularizing the model.\n",
    "\n",
    "2. **Batch Normalization**:\n",
    "    - A batch normalization layer (`nn.BatchNorm1d`) is added before the final classification layer. Batch normalization normalizes the output of the previous layer, which helps in speeding up the training process and providing some regularization.\n",
    "\n",
    "### Architecture Details\n",
    "\n",
    "1. **Initial Layers**:\n",
    "    - `conv1`: The first convolutional layer which applies a set of filters to the input image.\n",
    "    - `bn1`: Batch normalization layer to normalize the output of `conv1`.\n",
    "    - `relu`: ReLU activation function to introduce non-linearity.\n",
    "    - `maxpool`: Max pooling layer to reduce the spatial dimensions of the feature maps.\n",
    "\n",
    "2. **Residual Layers**:\n",
    "    - `layer1`, `layer2`, `layer3`, `layer4`: These are the residual blocks of the ResNet50 model. Each block consists of multiple convolutional layers with skip connections (residual connections) that help in preventing the vanishing gradient problem and allow the model to learn deeper representations.\n",
    "\n",
    "3. **Pooling Layer**:\n",
    "    - `avgpool`: Global average pooling layer that reduces the spatial dimensions to 1x1, creating a feature vector that summarizes the information from the feature maps.\n",
    "\n",
    "4. **Flattening**:\n",
    "    - The output of the average pooling layer is flattened to a 1-dimensional tensor, which is suitable for input to the fully connected layer.\n",
    "\n",
    "5. **Batch Normalization**:\n",
    "    - The flattened feature vector is passed through a batch normalization layer to stabilize and normalize the inputs to the final fully connected layer.\n",
    "\n",
    "6. **Fully Connected Layer with Dropout**:\n",
    "    - The batch-normalized features are then passed through the dropout layer and the final fully connected layer to produce the class scores.\n",
    "\n",
    "### Forward Pass\n",
    "\n",
    "During the forward pass, the input image `x` goes through the following steps:\n",
    "\n",
    "1. Convolution and pooling layers: `conv1 -> bn1 -> relu -> maxpool`\n",
    "2. Residual layers: `layer1 -> layer2 -> layer3 -> layer4`\n",
    "3. Average pooling: `avgpool`\n",
    "4. Flattening: `torch.flatten(x, 1)`\n",
    "5. Batch normalization: `batch_norm`\n",
    "6. Fully connected layer with dropout: `model.fc`\n",
    "\n",
    "### Summary\n",
    "\n",
    "The ModifiedResNet50 leverages the robust feature extraction capabilities of the pretrained ResNet50 model while tailoring the final layers to the specific task of four-class classification. The inclusion of dropout and batch normalization helps in regularizing the model, improving its generalization capabilities, and accelerating the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ModifiedResNet50, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm1d(num_ftrs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        x = self.model.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.model.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Regularization is a technique used to prevent overfitting, which occurs when a model fits the training data too well and fails to generalize to new data. Explanation of the Dropout layer:\n",
    "\n",
    "- `Dropout(0.5)`: During training, this layer randomly deactivates 50% of the neurons in the fully connected layer for each forward pass. This forces the network not to rely too much on certain neurons, helping to prevent overfitting.\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "Tuning the model's hyperparameters, such as the learning rate and optimizer, can significantly impact the model's performance. Changes made:\n",
    "\n",
    "Using the Adam optimizer with weight decay (L2 regularization). Explanation of the Adam optimizer:\n",
    "\n",
    "- `Adam`: An adaptive optimizer that adjusts the learning rates for each parameter. It is known for its effectiveness and efficiency in practice.\n",
    "- `weight_decay=1e-5`: This is an L2 regularization technique that penalizes large weights in the model, helping to prevent overfitting.\n",
    "\n",
    "Implementation of a learning rate scheduler. Explanation of the learning rate scheduler:\n",
    "\n",
    "- `ReduceLROnPlateau`: This scheduler reduces the learning rate when a metric (in this case, loss) has stopped improving. Specifically, it reduces the learning rate by a factor of 0.1 if there is no improvement in loss after 5 epochs.\n",
    "\n",
    "# Updated Training and Validation Functions\n",
    "\n",
    "Training function. Explanation of the training function:\n",
    "\n",
    "- `model.train()`: Puts the model in training mode.\n",
    "- `optimizer.zero_grad()`: Resets the optimizer's gradients before the backward pass.\n",
    "- `loss.backward()`: Computes the loss gradient with respect to the model's parameters.\n",
    "- `optimizer.step()`: Updates the model's parameters based on the computed gradients.\n",
    "- `scheduler.step(epoch_loss)`: Adjusts the learning rate based on the epoch loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ModifiedResNet50().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "def train_model(dataloader, model, criterion, optimizer, num_epochs):\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "    valid_acc_history = []\n",
    "    \n",
    "    best_model_wts = None\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(dataloader['train']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader['train'].dataset)\n",
    "        train_loss_history.append(epoch_loss)\n",
    "        \n",
    "        val_loss, val_acc = validate_model(dataloader['valid'], model, device, criterion)\n",
    "        valid_loss_history.append(val_loss)\n",
    "        valid_acc_history.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Train Loss: {epoch_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict().copy()\n",
    "    \n",
    "    print(f'Best Validation Accuracy: {best_acc}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    return train_loss_history, valid_loss_history, valid_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation function. Explanation of the validation function:\n",
    "\n",
    "- `model.eval()`: Puts the model in evaluation mode (disables dropout layers and other training-specific features).\n",
    "- `torch.no_grad()`: Disables gradient calculation, reducing memory usage and speeding up evaluation.\n",
    "- `torch.max(outputs, 1)`: Obtains the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(dataloader, model, device, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Explanation of the test function:\n",
    "\n",
    "- Similar to the validation function but calculates accuracy on the test dataset.\n",
    "\n",
    "Calculation and visualization of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_loss, valid_loss, valid_acc):\n",
    "    epochs = range(len(train_loss))\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, label='Train Loss')\n",
    "    plt.plot(epochs, valid_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss over Epochs')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, valid_acc, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "dataloader = {'train': train_dataloader, 'valid': valid_dataloader}\n",
    "\n",
    "num_epochs = 100\n",
    "train_loss, valid_loss, valid_acc = train_model(dataloader, model, criterion, optimizer, num_epochs)\n",
    "\n",
    "plot_metrics(train_loss, valid_loss, valid_acc)\n",
    "\n",
    "test_dataset = LungCancerDataset(root_dir='./data/test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def test_model(test_dataloader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy of the model on the test images: {100 * accuracy}%')\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "test_labels, test_predictions = test_model(test_dataloader, model, device)\n",
    "\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(16, 9))\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma'])\n",
    "ax.yaxis.set_ticklabels(['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma'])\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(test_labels, test_predictions, target_names=['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
